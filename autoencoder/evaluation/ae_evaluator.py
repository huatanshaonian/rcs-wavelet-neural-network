"""
AutoEncoderä¸“ç”¨è¯„ä¼°å™¨
é›†æˆé‡å»ºè´¨é‡è¯„ä¼°å’Œæ€§èƒ½åˆ†æ
"""

import torch
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
import time
import matplotlib.pyplot as plt
from .reconstruction_metrics import ReconstructionMetrics


class AE_Evaluator:
    """
    AutoEncoderç³»ç»Ÿè¯„ä¼°å™¨
    æ”¯æŒæ€§èƒ½è¯„ä¼°ã€å¯è§†åŒ–åˆ†æå’Œå¯¹æ¯”å®éªŒ
    """

    def __init__(self,
                 autoencoder,
                 parameter_mapper=None,
                 wavelet_transform=None,
                 device: Optional[torch.device] = None):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨

        Args:
            autoencoder: AutoEncoderæ¨¡å‹
            parameter_mapper: å‚æ•°æ˜ å°„å™¨ï¼ˆå¯é€‰ï¼‰
            wavelet_transform: å°æ³¢å˜æ¢å™¨ï¼ˆå¯é€‰ï¼‰
            device: è®¡ç®—è®¾å¤‡
        """
        self.autoencoder = autoencoder
        self.parameter_mapper = parameter_mapper
        self.wavelet_transform = wavelet_transform
        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        # ç§»åŠ¨æ¨¡å‹åˆ°è®¾å¤‡
        self.autoencoder.to(self.device)
        if self.parameter_mapper and hasattr(self.parameter_mapper, 'to'):
            self.parameter_mapper.to(self.device)

        # è¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨
        self.metrics_calculator = ReconstructionMetrics(device=self.device)

    def evaluate_autoencoder_reconstruction(self,
                                          test_rcs: np.ndarray,
                                          batch_size: int = 16) -> Dict[str, Any]:
        """
        è¯„ä¼°AutoEncoderé‡å»ºè´¨é‡

        Args:
            test_rcs: [N, 91, 91, 2] æµ‹è¯•RCSæ•°æ®
            batch_size: æ‰¹æ¬¡å¤§å°

        Returns:
            evaluation_results: è¯„ä¼°ç»“æœ
        """
        print("è¯„ä¼°AutoEncoderé‡å»ºè´¨é‡...")

        self.autoencoder.eval()

        # æ•°æ®é¢„å¤„ç†
        if self.wavelet_transform:
            rcs_tensor = torch.FloatTensor(test_rcs)
            test_wavelet = self.wavelet_transform.forward_transform(rcs_tensor)
        else:
            test_wavelet = torch.FloatTensor(test_rcs)

        # æ‰¹é‡é‡å»º
        reconstructed_data = []
        latent_representations = []
        inference_times = []

        n_batches = (len(test_wavelet) + batch_size - 1) // batch_size

        with torch.no_grad():
            for i in range(n_batches):
                start_idx = i * batch_size
                end_idx = min((i + 1) * batch_size, len(test_wavelet))

                batch_data = test_wavelet[start_idx:end_idx].to(self.device)

                # è®¡æ—¶
                start_time = time.time()

                # é‡å»º
                recon_batch, latent_batch = self.autoencoder(batch_data)

                inference_time = time.time() - start_time
                inference_times.append(inference_time)

                reconstructed_data.append(recon_batch.cpu())
                latent_representations.append(latent_batch.cpu())

        # åˆå¹¶ç»“æœ
        reconstructed_wavelet = torch.cat(reconstructed_data, dim=0)
        latent_vectors = torch.cat(latent_representations, dim=0)

        # è½¬æ¢å›RCSæ ¼å¼
        if self.wavelet_transform:
            reconstructed_rcs = self.wavelet_transform.inverse_transform(reconstructed_wavelet)
        else:
            reconstructed_rcs = reconstructed_wavelet

        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        true_rcs_tensor = torch.FloatTensor(test_rcs)
        metrics = self.metrics_calculator.compute_all_metrics(reconstructed_rcs, true_rcs_tensor)

        # æ€§èƒ½ç»Ÿè®¡
        avg_inference_time = np.mean(inference_times)
        total_samples = len(test_rcs)
        samples_per_second = total_samples / sum(inference_times)

        # éšç©ºé—´åˆ†æ
        latent_analysis = self._analyze_latent_space(latent_vectors.numpy())

        results = {
            'reconstruction_metrics': metrics,
            'performance': {
                'avg_inference_time': avg_inference_time,
                'samples_per_second': samples_per_second,
                'total_samples': total_samples
            },
            'latent_analysis': latent_analysis,
            'reconstructed_rcs': reconstructed_rcs.numpy(),
            'latent_vectors': latent_vectors.numpy()
        }

        print(f"AEé‡å»ºè¯„ä¼°å®Œæˆ: MSE={metrics['mse']:.6f}, SSIM={metrics['ssim_mean']:.4f}")

        return results

    def evaluate_parameter_mapping(self,
                                  test_params: np.ndarray,
                                  test_rcs: np.ndarray) -> Dict[str, Any]:
        """
        è¯„ä¼°å‚æ•°æ˜ å°„è´¨é‡

        Args:
            test_params: [N, 9] æµ‹è¯•å‚æ•°
            test_rcs: [N, 91, 91, 2] æµ‹è¯•RCS

        Returns:
            evaluation_results: è¯„ä¼°ç»“æœ
        """
        if self.parameter_mapper is None:
            raise ValueError("å‚æ•°æ˜ å°„å™¨æœªè®¾ç½®ï¼Œæ— æ³•è¿›è¡Œè¯„ä¼°")

        print("è¯„ä¼°å‚æ•°æ˜ å°„è´¨é‡...")

        # 1. è·å–ç›®æ ‡éšç©ºé—´è¡¨ç¤º
        self.autoencoder.eval()

        if self.wavelet_transform:
            rcs_tensor = torch.FloatTensor(test_rcs)
            test_wavelet = self.wavelet_transform.forward_transform(rcs_tensor)
        else:
            test_wavelet = torch.FloatTensor(test_rcs)

        with torch.no_grad():
            test_wavelet = test_wavelet.to(self.device)
            _, target_latent = self.autoencoder(test_wavelet)
            target_latent = target_latent.cpu().numpy()

        # 2. å‚æ•°æ˜ å°„é¢„æµ‹
        if hasattr(self.parameter_mapper, 'predict'):
            # ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹
            pred_latent = self.parameter_mapper.predict(test_params)
            mapping_metrics = self.parameter_mapper.evaluate(test_params, target_latent)
        else:
            # æ·±åº¦å­¦ä¹ æ¨¡å‹
            self.parameter_mapper.eval()
            with torch.no_grad():
                params_tensor = torch.FloatTensor(test_params).to(self.device)
                pred_latent = self.parameter_mapper(params_tensor).cpu().numpy()

            # è®¡ç®—æ˜ å°„æŒ‡æ ‡
            mapping_mse = np.mean((target_latent - pred_latent) ** 2)
            mapping_r2 = 1 - np.sum((target_latent - pred_latent) ** 2) / np.sum((target_latent - np.mean(target_latent)) ** 2)

            mapping_metrics = {
                'mse': mapping_mse,
                'r2_score': mapping_r2
            }

        # 3. éšç©ºé—´ä¸€è‡´æ€§åˆ†æ
        latent_consistency = self._analyze_latent_consistency(target_latent, pred_latent)

        results = {
            'mapping_metrics': mapping_metrics,
            'latent_consistency': latent_consistency,
            'target_latent': target_latent,
            'predicted_latent': pred_latent
        }

        print(f"å‚æ•°æ˜ å°„è¯„ä¼°å®Œæˆ: MSE={mapping_metrics['mse']:.6f}, RÂ²={mapping_metrics.get('r2_score', 0):.4f}")

        return results

    def evaluate_end_to_end(self,
                           test_params: np.ndarray,
                           test_rcs: np.ndarray) -> Dict[str, Any]:
        """
        ç«¯åˆ°ç«¯è¯„ä¼°ï¼šå‚æ•° â†’ RCSé‡å»º

        Args:
            test_params: [N, 9] æµ‹è¯•å‚æ•°
            test_rcs: [N, 91, 91, 2] æµ‹è¯•RCS

        Returns:
            evaluation_results: è¯„ä¼°ç»“æœ
        """
        if self.parameter_mapper is None:
            raise ValueError("å‚æ•°æ˜ å°„å™¨æœªè®¾ç½®ï¼Œæ— æ³•è¿›è¡Œç«¯åˆ°ç«¯è¯„ä¼°")

        print("æ‰§è¡Œç«¯åˆ°ç«¯è¯„ä¼°...")

        # 1. å‚æ•° â†’ éšç©ºé—´
        if hasattr(self.parameter_mapper, 'predict'):
            pred_latent = self.parameter_mapper.predict(test_params)
            pred_latent = torch.FloatTensor(pred_latent)
        else:
            self.parameter_mapper.eval()
            with torch.no_grad():
                params_tensor = torch.FloatTensor(test_params).to(self.device)
                pred_latent = self.parameter_mapper(params_tensor)

        # 2. éšç©ºé—´ â†’ å°æ³¢ç³»æ•°
        self.autoencoder.eval()
        with torch.no_grad():
            pred_latent = pred_latent.to(self.device)
            pred_wavelet = self.autoencoder.decode(pred_latent)

        # 3. å°æ³¢ç³»æ•° â†’ RCS
        if self.wavelet_transform:
            pred_rcs = self.wavelet_transform.inverse_transform(pred_wavelet.cpu())
        else:
            pred_rcs = pred_wavelet.cpu()

        # 4. è®¡ç®—é‡å»ºè´¨é‡
        true_rcs_tensor = torch.FloatTensor(test_rcs)
        e2e_metrics = self.metrics_calculator.compute_all_metrics(pred_rcs, true_rcs_tensor)

        # 5. ä¸ç›´æ¥AEé‡å»ºå¯¹æ¯”
        if self.wavelet_transform:
            rcs_tensor = torch.FloatTensor(test_rcs)
            true_wavelet = self.wavelet_transform.forward_transform(rcs_tensor)
        else:
            true_wavelet = torch.FloatTensor(test_rcs)

        with torch.no_grad():
            true_wavelet = true_wavelet.to(self.device)
            direct_recon, _ = self.autoencoder(true_wavelet)

        if self.wavelet_transform:
            direct_rcs = self.wavelet_transform.inverse_transform(direct_recon.cpu())
        else:
            direct_rcs = direct_recon.cpu()

        direct_metrics = self.metrics_calculator.compute_all_metrics(direct_rcs, true_rcs_tensor)

        results = {
            'end_to_end_metrics': e2e_metrics,
            'direct_reconstruction_metrics': direct_metrics,
            'performance_comparison': {
                'e2e_mse': e2e_metrics['mse'],
                'direct_mse': direct_metrics['mse'],
                'mse_ratio': e2e_metrics['mse'] / max(direct_metrics['mse'], 1e-8),
                'e2e_ssim': e2e_metrics['ssim_mean'],
                'direct_ssim': direct_metrics['ssim_mean']
            },
            'predicted_rcs': pred_rcs.numpy(),
            'direct_reconstructed_rcs': direct_rcs.numpy()
        }

        print(f"ç«¯åˆ°ç«¯è¯„ä¼°å®Œæˆ:")
        print(f"  E2E MSE: {e2e_metrics['mse']:.6f}")
        print(f"  ç›´æ¥é‡å»º MSE: {direct_metrics['mse']:.6f}")
        print(f"  MSEæ¯”å€¼: {results['performance_comparison']['mse_ratio']:.2f}")

        return results

    def _analyze_latent_space(self, latent_vectors: np.ndarray) -> Dict[str, Any]:
        """åˆ†æéšç©ºé—´ç‰¹æ€§"""

        analysis = {}

        # åŸºç¡€ç»Ÿè®¡
        analysis['shape'] = latent_vectors.shape
        analysis['mean'] = np.mean(latent_vectors, axis=0)
        analysis['std'] = np.std(latent_vectors, axis=0)
        analysis['min'] = np.min(latent_vectors, axis=0)
        analysis['max'] = np.max(latent_vectors, axis=0)

        # ç»´åº¦åˆ©ç”¨ç‡
        dimension_usage = np.std(latent_vectors, axis=0)
        active_dims = np.sum(dimension_usage > 0.01)  # æ ‡å‡†å·®å¤§äº0.01çš„ç»´åº¦
        analysis['active_dimensions'] = active_dims
        analysis['dimension_usage_ratio'] = active_dims / latent_vectors.shape[1]

        # ç›¸å…³æ€§åˆ†æ
        correlation_matrix = np.corrcoef(latent_vectors.T)
        mean_correlation = np.mean(np.abs(correlation_matrix[np.triu_indices_from(correlation_matrix, k=1)]))
        analysis['mean_correlation'] = mean_correlation

        return analysis

    def _analyze_latent_consistency(self,
                                  target_latent: np.ndarray,
                                  pred_latent: np.ndarray) -> Dict[str, float]:
        """åˆ†æéšç©ºé—´ä¸€è‡´æ€§"""

        # é€ç»´åº¦ç›¸å…³æ€§
        dim_correlations = []
        for i in range(target_latent.shape[1]):
            corr = np.corrcoef(target_latent[:, i], pred_latent[:, i])[0, 1]
            if not np.isnan(corr):
                dim_correlations.append(corr)

        # æ•´ä½“ç›¸å…³æ€§
        overall_correlation = np.corrcoef(target_latent.flatten(), pred_latent.flatten())[0, 1]

        # ç»´åº¦é‡è¦æ€§åˆ†æ
        dim_importance = np.std(target_latent, axis=0)
        weighted_correlation = np.average(dim_correlations, weights=dim_importance[:len(dim_correlations)])

        return {
            'overall_correlation': overall_correlation if not np.isnan(overall_correlation) else 0.0,
            'mean_dim_correlation': np.mean(dim_correlations) if dim_correlations else 0.0,
            'weighted_correlation': weighted_correlation if not np.isnan(weighted_correlation) else 0.0,
            'num_valid_dims': len(dim_correlations)
        }

    def generate_comprehensive_report(self,
                                    ae_results: Dict[str, Any],
                                    mapping_results: Optional[Dict[str, Any]] = None,
                                    e2e_results: Optional[Dict[str, Any]] = None) -> str:
        """ç”Ÿæˆç»¼åˆè¯„ä¼°æŠ¥å‘Š"""

        report = "\\n" + "="*60 + "\\n"
        report += "           AutoEncoderç³»ç»Ÿç»¼åˆè¯„ä¼°æŠ¥å‘Š\\n"
        report += "="*60 + "\\n"

        # AutoEncoderé‡å»ºè¯„ä¼°
        report += "\\nğŸ”§ AutoEncoderé‡å»ºè¯„ä¼°:\\n"
        report += "-" * 40 + "\\n"

        ae_metrics = ae_results['reconstruction_metrics']
        performance = ae_results['performance']

        report += f"é‡å»ºè´¨é‡æŒ‡æ ‡:\\n"
        report += f"  MSE:           {ae_metrics['mse']:.6f}\\n"
        report += f"  SSIM:          {ae_metrics['ssim_mean']:.4f} Â± {ae_metrics['ssim_std']:.4f}\\n"
        report += f"  ç›¸å…³ç³»æ•°:       {ae_metrics['correlation']:.4f}\\n"
        report += f"  RÂ²å†³å®šç³»æ•°:     {ae_metrics['r2_score']:.4f}\\n"

        report += f"\\næ€§èƒ½æŒ‡æ ‡:\\n"
        report += f"  æ¨ç†é€Ÿåº¦:       {performance['samples_per_second']:.1f} æ ·æœ¬/ç§’\\n"
        report += f"  å¹³å‡æ¨ç†æ—¶é—´:    {performance['avg_inference_time']*1000:.2f} ms\\n"

        latent_analysis = ae_results['latent_analysis']
        report += f"\\néšç©ºé—´åˆ†æ:\\n"
        report += f"  æ´»è·ƒç»´åº¦:       {latent_analysis['active_dimensions']}/{latent_analysis['shape'][1]}\\n"
        report += f"  ç»´åº¦åˆ©ç”¨ç‡:     {latent_analysis['dimension_usage_ratio']:.2f}\\n"

        # å‚æ•°æ˜ å°„è¯„ä¼°
        if mapping_results:
            report += "\\nğŸ¯ å‚æ•°æ˜ å°„è¯„ä¼°:\\n"
            report += "-" * 40 + "\\n"

            mapping_metrics = mapping_results['mapping_metrics']
            consistency = mapping_results['latent_consistency']

            report += f"æ˜ å°„è´¨é‡:\\n"
            report += f"  MSE:           {mapping_metrics['mse']:.6f}\\n"
            report += f"  RÂ²:            {mapping_metrics.get('r2_score', 0):.4f}\\n"

            report += f"\\néšç©ºé—´ä¸€è‡´æ€§:\\n"
            report += f"  æ•´ä½“ç›¸å…³æ€§:     {consistency['overall_correlation']:.4f}\\n"
            report += f"  ç»´åº¦å¹³å‡ç›¸å…³æ€§: {consistency['mean_dim_correlation']:.4f}\\n"

        # ç«¯åˆ°ç«¯è¯„ä¼°
        if e2e_results:
            report += "\\nğŸ”„ ç«¯åˆ°ç«¯è¯„ä¼°:\\n"
            report += "-" * 40 + "\\n"

            e2e_metrics = e2e_results['end_to_end_metrics']
            comparison = e2e_results['performance_comparison']

            report += f"ç«¯åˆ°ç«¯é‡å»ºè´¨é‡:\\n"
            report += f"  MSE:           {e2e_metrics['mse']:.6f}\\n"
            report += f"  SSIM:          {e2e_metrics['ssim_mean']:.4f}\\n"

            report += f"\\næ€§èƒ½å¯¹æ¯”:\\n"
            report += f"  E2E vs ç›´æ¥é‡å»º:\\n"
            report += f"    MSEæ¯”å€¼:     {comparison['mse_ratio']:.2f}\\n"
            report += f"    SSIMå·®å¼‚:    {comparison['e2e_ssim'] - comparison['direct_ssim']:.4f}\\n"

        # æ€»ç»“
        report += "\\nğŸ“‹ è¯„ä¼°æ€»ç»“:\\n"
        report += "-" * 40 + "\\n"

        # æ ¹æ®æŒ‡æ ‡ç»™å‡ºè¯„ä¼°ç»“è®º
        if ae_metrics['ssim_mean'] > 0.8:
            ae_quality = "ä¼˜ç§€"
        elif ae_metrics['ssim_mean'] > 0.6:
            ae_quality = "è‰¯å¥½"
        else:
            ae_quality = "éœ€è¦æ”¹è¿›"

        report += f"AutoEncoderé‡å»ºè´¨é‡: {ae_quality}\\n"

        if mapping_results and mapping_results['mapping_metrics'].get('r2_score', 0) > 0.8:
            mapping_quality = "ä¼˜ç§€"
        elif mapping_results and mapping_results['mapping_metrics'].get('r2_score', 0) > 0.6:
            mapping_quality = "è‰¯å¥½"
        else:
            mapping_quality = "éœ€è¦æ”¹è¿›"

        if mapping_results:
            report += f"å‚æ•°æ˜ å°„è´¨é‡: {mapping_quality}\\n"

        report += "\\n" + "="*60

        return report


def test_ae_evaluator():
    """æµ‹è¯•AEè¯„ä¼°å™¨"""
    print("=== AEè¯„ä¼°å™¨æµ‹è¯• ===")

    # è¿™é‡Œéœ€è¦å®é™…çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•
    # ç”±äºå¯¼å…¥é—®é¢˜ï¼Œæš‚æ—¶ä½¿ç”¨æ¨¡æ‹Ÿæµ‹è¯•

    print("AEè¯„ä¼°å™¨æ¨¡å—åˆ›å»ºå®Œæˆ")
    print("åŒ…å«ä»¥ä¸‹åŠŸèƒ½:")
    print("- AutoEncoderé‡å»ºè´¨é‡è¯„ä¼°")
    print("- å‚æ•°æ˜ å°„è´¨é‡è¯„ä¼°")
    print("- ç«¯åˆ°ç«¯æ€§èƒ½è¯„ä¼°")
    print("- éšç©ºé—´åˆ†æ")
    print("- ç»¼åˆè¯„ä¼°æŠ¥å‘Šç”Ÿæˆ")

    return True


if __name__ == "__main__":
    test_ae_evaluator()